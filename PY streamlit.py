import streamlit as st
import os
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI

# --- 专转 驻转 砖 砖注 拽 ---
MY_NEW_KEY = "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"

# 拽  砖砖 -Secrets 注
if "OPENAI_API_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_API_KEY"]
else:
    api_key = MY_NEW_KEY


# --- 专转 祝 ---
st.set_page_config(page_title="注专 -PDF ", page_icon="")

st.markdown("""<style>.stApp {direction: RTL; text-align: right;}</style>""", unsafe_allow_html=True)
st.title(" 爪' 注 住 -PDF 砖")

# --- 注转 住住 转 注 ---
db_path = "vectorstore_db"

@st.cache_resource
def get_vector_db():
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    if os.path.exists(db_path):
        return FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
    else:
        st.error("砖: 转拽转 vectorstore_db  爪 -GitHub!")
        st.stop()

vector_db = get_vector_db()

# ---  爪' ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("砖 转 注 住..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # 驻砖 住
        docs = vector_db.similarity_search(prompt, k=3)
        context = "\n".join([d.page_content for d in docs])
        
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, openai_api_key=api_key)
        full_prompt = f"Context:\n{context}\n\nQuestion: {prompt}\n注 注专转 注 住 拽砖专."
        
        try:
            response = llm.invoke(full_prompt).content
            st.markdown(response)
            st.session_state.messages.append({"role": "assistant", "content": response})
        except Exception as e:
            st.error(f"砖: {e}")
